---
title: "初探 Fabric 架构"
date: 2021-10-15T16:04:56+08:00
draft: false
slug: fabric
image: "method-draw-image.svg"
description: "学习 fabric 的设计理念"
categories:
    - 学习
tags: 
    - fabric
---

## 整体架构

本节参考了 [Hyperledger Fabric: A Distributed Operating System for Permissioned Blockchains](https://arxiv.org/abs/1801.10228) 论文。

根据官网对于 fabric 的一些定义，不难发现 fabric 与一般的构建弹性程序的方法别无二致。比如产生交易都是想要把 ledger 复制到不同的 peer 节点上，再通过一定的验证机制来保证数据的一致性和可靠性。但其实 fabric 与**普通的构建弹性程序的方法**——SMR（state-machine replication) 还是有几点区别的：

> (1) not only one, but many distributed applications run concurrently; 
>
> (2) applications may be deployed dynamically and by anyone; 
>
> (3) the application code isuntrusted, potentially even malicious.

1. 复制操作可能是并发的，甚至并行的。
2. 应用可能随时随地地被任何人部署。
3. 不能完全信任应用的代码，可能会存在应用恶意攻击的可能。

现在（提出 fabric 的那几年）很多支持智能合约的区块链走的都是 SMR 的老路—— active replication: 通过一个共识的或者能够保证原子传播的协议，这个协议先将事务排序，并且发送给所有的 peer，每个 peer 按照顺序执行这些事务。（note：交易、事务都被称为 transaction，此处语境使用交易或者事务都可用）

这样的操作被称为**顺序执行架构**；它要求所有节点执行每一个事务，并且所有事务都是确定性的。市面上几乎所有的区块链项目都是基于这样的架构，这导致了几个问题：

1. 采用的共识协议被硬编码到了平台中（区块链服务可被称为一个平台，Paas）。这样的做法是非常经典的“一刀切”，没有根据实际情况来选择不同的共识协议。
2. 如上所说，交易验证的信任模型是被共识协议决定的，不能修改共识协议意味着不能同时满足不同智能合约的需求。
3. 智能合约必须用特定的编程语言编写，这会阻碍社区的发展。
4. 要求所有节点顺序执行事务导致了性能瓶颈，并且可能会引来 dos（denial-of-service) 攻击
5. 交易必须是确定性的，这在程序上可能很难保证。
6. 每个智能合约运行在所有的 peer 节点上，这与保密性产生了冲突，并且拒绝把智能合约的代码传播给这个 peer 节点的子集。

因此，fabric 设计了一个新的架构来实现 resiliency, flexibility, scalability, confidentiality（弹性、灵活性、可扩展性和保密性），允许使用标准编程语言写的智能合约代码在不同的节点上一致地执行。因此，fabric 自称为**为联盟链设计的操作系统**。

这种架构允许不被信任的代码分布式地在不被信任的环境中执行，被称为 execute-order-validate 范式。它将交易流程分为三个步骤，可以在系统中的不同实体上运行：

1. 执行交易并检查其正确性，从而为它背书 (endorse)（对应其他区块链中的“交易验证”）；
2. 通过共识协议排序这些交易，而不是根据交易语义进行排序； 
3. 根据特定应用的信任假设进行交易验证，这也是为了防止并发带来的竞争。

针对复制，fabric 结合了两种主流的复制方式：被动复制和主动复制。

fabric 用的被动复制也可以被称为主从备份，在分布式数据库中非常常见，但是增加了**基于中间件的不对称更新（asymmetric update）处理**，并被移植到有拜占庭故障的不信任环境。在 fabric 中，每笔交易只需要一系列 peer 中的子集执行（背书）即可，这意味着可以并行地执行这些操作，并且解决了潜在的不确定性问题（借鉴了 execute-verify BFT 的流程）。灵活的背书策略可以适应不同的智能合约的需求，比如需要多少人来背书。

> In Fabric, every transaction is executed (endorsed) only by a subset of the peers, which allows for parallel execution and addresses potential non-determinism, draw-ing on “execute-verify” BFT replication
>
> **为什么可以解决 potential non-determinism** ？

fabric 的主动复制指的是每个单独的 peer 节点会单独执行一个具有决定性的验证步骤，交易只在这次验证达成**全序范围内的共识** (total order) 时才写入账本。这使得 fabric 可以根据不同的背书策略来建立不同的信任假设。

为了实现上述特性，fabric 设计了下面的几个模块：

* 排序服务（ordering service）： 自动向每个 peer 节点发送状态的更新，并基于交易的顺序建立共识。
* MSP（membership service provider）：将用户和加密后的身份联系起来
* peer-to-peer gossip service：通过排序服务来减少区块的输出（可选）
* 智能合约（smart contracts）：可以使用标准编程语言撰写，不会对账本的状态有直接的修改。每个智能合约都是运行在容器中，确保了隔离性。
* 账本（ledger）：每个 peer 本地都维护着仅追加的区块形式的账本，相当于是最近的 key-value 存储状态的一个快照。

下面详细介绍了一下之前提到的概念。

### Order-Execute 架构的问题

在 fabric 之前的区块链使用的都是 order-execute 架构。这意味着区块链网络先使用一个共识协议排序这些交易，所有 peer 节点再以这个相同的顺序执行这些交易。

比如需要工作量机制的区块链的执行流程如下：

1. 每个 peer 节点（即参与共识的节点）都会组成一个包含有效交易的区块（为了建立有效性，该 peer 节点已经预先执行了这些交易）。
2. 这个 peer 节点尝试参与工作量证明。如果是比特币的话，这个步骤就是挖矿。
3. 如果这个节点挖到矿了，就会把自己的区块传播给其他的节点
4. 每个收到这个区块的节点都会验证这个结果是否正确，如果正确，则会按顺序执行这个区块里的交易，从而保证了顺序一致性。

**Sequential execution** 这种方式限制了区块链的吞吐量，而且吞吐量往往和延迟成反比，这意味着这一部分可能会成为区块链的性能瓶颈。分布式系统的文献中提出了许多解决方法来提升性能，比如并行执行不相关的操作。但是在区块链中，这些方法行不通。比如在推导这些操作之间的关系的时候，这可能会涉及到一些隐私性的内容，这与保密性相违背。而且，这种方法也不能解决来自不信任者的 Dos 攻击。

Order-Execute 架构的另一个问题是**非确定性事务**（交易）。在活跃的 SMR（state machine replication）中，经过共识协议后的操作必须是确定性的，否则会导致不同的节点有不同的状态。在以太坊中，是通过创建一种新的编程语言来实现这个需求的。但这也意味着需要额外的学习成本，那能不能用大家熟知的编程语言呢？

不幸的是，就算应用的编写者不自己写出一段具有不确定性的代码，通用编程语言的内部实现可能并不能保证结果是唯一的（即不能保证确定性），比如 Go 语言中的 map iterator。更糟糕的是，不能保证应用的编写者自己不出错，甚至是写出恶意的代码。

Order-Execute 架构还要考虑的一点是**执行的保密性**（Confidentiality of execution）。许可链中很多的使用场景都要求有保密性，即限制对智能合约逻辑、交易数据或者账本状态的访问。虽然加密技术（数据加密、零知识证明、可验证计算）可以实现保密性，但是这样的开销相当大。

幸运的是，能够将相同的状态传播给所有的 peer 就足够了，并不需要在每个 peer 上执行相同的代码。因此，执行一个智能合约的工作只需要所有 peer 的子集（这个子集是被信任的）来完成即可，他们能够为执行的结果做担保。这种设计根据区块链的信任模型把主动复制演变成了被动复制。

### 现有架构的问题

#### 信任模型是固定的-应当更加灵活

多数许可链依赖异步的 BFT 复制协议来建立共识。这种协议是基于不超过三分之一的节点失效（超过三分之二的节点正常运行）的安全假设的（即拜占庭容错）。在这种相同的安全假设下，尽管事实上可能只需要把 BFT 限制到少数几个节点，但相同的 peer 也经常执行应用程序。在这种环境中，可能仍然不能完全满足智能合约的需求。因为智能合约可能还会考虑每个 peer 的身份，来作为信任条件的一部分。因此，一个通用的区块链应该将协议上的信任和应用上的信任解耦，形成一个更加灵活的信任模型。

#### 共识协议是硬编码的-应该是可替换的

没有一个协议能够适应所有的场景，不同的 BFT 协议在不同的环境下的性能有非常大的差距。BFT 共识应该是天生可重新配置的，最好是能够动态适应环境的变化。另一个重要的点是应该将协议的信任假设与特定的区块链部署场景相匹配。事实上，人们可能想用一种基于其他信任模型的协议来取代 BFT 共识，如 XFT（cross fault tolerance），或 CFT(crash fault tolerance) 协议，如 Paxos/Raft 和 ZooKeeper，甚至是一种无许可协议。

### 改进后的 fabric

fabric 将一贯的 order-execute 两部曲修正成了 execute-order-validate 三部曲。

![Figure 2: Execute-order-validate architecture of Fabric](fig2.png)

简言之，fabric 中的一个分布式应用包括两部分：

* 智能合约，也叫做链码。是应用的具体逻辑，在 execute 这个步骤的时候运行。链码是 fabric 分布式应用的重要部分，可能被不被信任的开发者编写。其中还包含一些特殊的链码，叫做系统链码（system chaincodes），主要负责管理区块链系统和维护变量。
* 在 validate 步骤时，一个背书策略会被启用。背书策略本身无法被不被信任的开发者修改，通常是作为静态库的形式使用，因此唯一能做的就是通过链码来设置一些背书策略的参数。只有被指定的管理者才有权利通过系统管理函数修改背书策略。一个典型的背书策略让链码确定一组有背书权的 peer 来进行背书操作（类比许可证发布中心）。背书策略在集合上使用单调的逻辑表达，比如 "五分之三 "或"(A∧B)∨C"。自定义背书政策可以实现任意的逻辑。

客户端向被背书策略指定的 peer 们发送交易，每个交易会被这些 peers 执行，并且其输出会被记录。这个步骤也叫做**背书**。执行完成后，交易就进入到了 order 的阶段，这个阶段使用了一个可插拔的共识协议来产生一个**被背书的**且**按 block 分组的**交易的全序序列。这个顺序广播给了所有的节点。

**主动复制完全是对于交易的输入进行排序，而 fabric 这里是对 在 execute 步骤计算出的交易的输出加上状态依赖进行排序。然后每个 peer 在 validate 阶段根据背书策略和执行的一致性来验证状态的变化。所有的 peer 会以同样的顺序来验证这些交易，并且这个验证是确定性的。**

在这个意义上，Fabric 在拜占庭模型中引入了一种全新的混合复制模式，它结合了被动复制（the pre-consensus computation of state updates）和主动复制（the post-consensus validation of execution results and state changes）。

fabric 还包含了一组来自网络（network） 的节点。

![Figure 3: A Fabric network with federated MSPs and runningmultiple (differently shaded and colored) chaincodes, selectively installed on peers according to policy.](fig3.png)

因为 fabric 是被许可的，所以所有参与网络的节点都有一个身份，由 MSP（membership service provider）模块提供。所有在网络中的节点承担着下面三个角色中的一个：

* 客户端在 execute 阶段开始时提交 transaction proposals，节点在 excute 阶段帮助协调，并且为排序阶段广播这些交易。
* Peers 执行 transaction proposals 并且验证 transactions。所有的 peer 都维护着区块链账本，也被称为 state。并不是所有的 peer 都会执行 transaction proposals，只有其中的子集（也就是上述的背书者）会这么做。
* 排序服务节点整体上构成了排序服务。简而言之，排序服务建立了 Fabric 中所有事务的全序，其中每个事务包含执行阶段计算的状态更新和依赖关系，以及背书者节点的加密签名。排序节点完全不知道应用程序的状态，也不参与交易的执行和验证。这种设计选择使 Fabric 中的共识尽可能地模块化，并简化了 Fabric 中共识协议的替换。

Fabric 网络实际上支持不同的区块链使用同一组排序服务。这样的区块链叫做 channel，并且可能有不同的 peers 作为他的成员。通道可以用来划分区块链网络的状态，但通道之间的共识是不协调的，每个通道中的交易总顺序与其他通道是分开的（不同的）。**认为所有排序节点都是可信的**的这么一个部署可以对所有的 peer 进行一个通道访问权限控制。

#### 执行

在执行阶段，客户端签署并且向一个或多个背书者发送 transaction proposal。一个 proposal 包含着这个客户的身份（由 MSP 给出）、要执行的这个操作的载荷和参数、这个链码的标识符、本次使用的一个随机数、由这个随机数生成的客户端标识符。

背书者会模拟（simulate）这个提议（proposal），这个词语在后面还会被提到。模拟的意思就是背书者会根据链码中定义的操作，**根据自己本地的区块链状态**先执行一遍（不与其他人同步），这个操作是在容器里的，与主进程隔离，所以不会有副作用。

背书者也不会把结果持久化到账本状态里，区块链状态是由 peer transaction manager（PTM）维护的，在后续会提到。一个链码创建的状态不能被其他的链码直接访问。注意，链码不需要维护维护程序代码中的本地状态，只需要维护他在区块链中的状态。可以通过 GetState，PutState，DelState 三个 api 进行访问。当然，如果有许可的话，一个链码可以调用另一个链码，通过同一个通道中的状态。

作为模拟的结果，每个背书者都会产生一个叫做 writeset 的值，包含要更新的状态（比如新增 kv，或者更新某个 key）；也会产生一个叫做 readset 的值，包含这次模拟需要的一些依赖（比如这次模拟是根据某个 version 的 kv 计算出来的）。在模拟结束之后，背书者会签署（并加密）一条叫做 endorsement 的消息，这个信息除了包含 writeset 和 readset 之外还包括一些元数据，比如事务 id，背书者 id，背书者签名。这个消息会以 proposal response 的形式回复给 client。客户端收集这些背书回复，直到满足了链码的背书策略。另外，还要求贝格背书者产生的结果（writeset、readset）是一样的，然后客户端将继续创建交易，传递给排序服务。下图是调用流程图：

![Fabric high level transaction flow](fig4.png)

现在讨论一下不同的设计风格。因为背书者在模拟 proposal 的时候没有和其他的背书者同步，所以不同的背书者可能当时的状态不一样，导致产生的结果也不一样。在标准的背书政策里有要求背书者们产生的结果是相同的，这意味着在访问相同的 key 的时候会产生竞争，从而导致客户无法满足背书政策的要求。

针对这个问题，数据库主从复制是通过中间件来实现同步的，这样假设的结果是区块链不信任一个单独的 peer 的执行是正确的。（虽然没懂什么意思）但是这种设计方式简化了架构，并且已经足够满足区块链应用的需求：在正常情况下，如果两个 peer 的当前状态是相同的，那么可以减少甚至消除这种情况下执行操作引起的竞争。

在排序阶段之前试运行事务对于保证链码的确定性是非常重要的。如果链码是不确定的，就可能会被终止运行，因为客户端需要收到足够数量的结果一致的 proposal response。这对于 order-execute 架构是个优势，后者操作的不确定性可能会导致 peer 的状态不一致。

另外，这样的实现方式也可以解决来自不受信任的链码的 DoS 攻击。因为如果怀疑受到了 DoS 攻击的话，他可以根据本地策略简单地终止执行，且不会影响系统的一致性。但是这种单方终止在 order-execute 架构中是不可能的。

#### 排序

当客户端收到足够多的提案背书后，他就会正式发起一个交易并且提交给排序服务。这个交易包含了有效载荷（即带参数的链码操作）、交易元数据和背书。排序阶段对每个通道提交的事务进行排序，建立一个总序（total order）。换句话说，排序意味着会广播背书，然后建立一个基于交易的共识，尽管排序节点可能出错。此外，排序服务会将多个交易分批打包进区块，并且输出包含交易的区块的哈希链序列（hash-chained sequence）。将交易进行分组织或者分批打包可以提高广播协议的吞吐量，这是一种非常出名的用于容错广播的技术。

排序服务只为 peer 节点提供了两个 api，并且由通道标识符隐式参数化。

* boardcast(tx)：用于广播一个交易 tx，tx 通常包括有效载荷和客户的签名。
* B<-deliver(s)：用非负数的序列号 s 去搜索区块 B。这个区块包含一个区块的列表 [tx1, ..., txk] 和一个 hash-chain 类型的值 h，h 表示这个区块有 s-1 这个序列号。比如`B=([tx1, ..., txk], h)`。客户端可能会多次调用这个方法，结果应该是一直返回相同的区块（如果服务可用）。可以这么说：peer 第一次通过调用 deliver(s) 收到 B 时，意味着 peer 交付了带有序列号 s 的区块 B。

排序服务保证了在一个通道中被交付的区块是全序的，排序保证了下面的几个通道的属性是安全的：

* **Agreement**: 如果两个区块的序列号 s 相同，则两个区块 B, B'相同。
* **Hash chain integrity**: 如果一个正确的区块 B 带有的序号是 s，而另一个正确的区块 B'=([tx1, ..., txk], h') 带有的序号是 s+1，则 h'一定等于 H(B)，其中 H(*) 表示的是一个哈希函数。
* **No skipping**：如果一个正确的 peer 节点 p 交付了一个序号 s>0 的区块 B，则 p 一定已经交付了带有**在 [0, s-1] 的区间内的序号的**区块。
* **No creation**：当一个正确的 peer 节点交付带有序号为 s 的区块 B，则对于这个区块里的每一个交易 tx，一定有一些客户端已经广播了 tx。
* **Validity**：最终一致性，如果一个正确的客户端调用了 boardcast(tx)，则每个正确的 peer 节点最终都会交付一个带有 tx 的区块，以及对应的一个序列号。

尽管如此，每个单独的排序实现都被允许有自己的有效性和公平性保证，以满足客户的请求。

由于区块链网络中可能有大量的 peer 节点，但预计只有相对较少的节点会实现排序服务，因此 Fabric 可以被配置为使用内置的 gossip service，将排序服务交付的区块传播给所有 peer。gossip 的实现是可扩展的，并且与排序服务的特定实现无关，因此它可以与 CFT 和 BFT 的排序服务一起工作，确保 Fabric 的模块化。

排序服务也可以执行访问控制检查，看看客户端是否被允许在一个给定的通道上广播消息或接收区块。

再次讨论一下这么设计的原因。排序服务不包含任何区块链的状态， 也不进行验证或者执行交易，这非常的重要。这使得 fabric 成为第一个将共识与执行、验证分离的区块链系统。这使得共识可以尽可能地模块化，而且可以打造一个实现了排序服务的共识协议的生态系统。**Hash chain integrity** 以及区块链的存在只是为了让 peer 节点对于区块序列的完整性验证更加有效。最后注意一点，我们并不要求排序服务具备防止重复交易的功能，这简化了他的实现。因为重复的交易会在**验证**环节中被 peer 的读写检查过滤。

#### 验证

区块被排序服务或者 gossip 直接交付给 peer 节点。然后，一个新的区块进入了验证阶段，该阶段包括以下的三个步骤：

1. **endorsement policy evaluation**：背书策略的评估对区块内的所有交易并行执行。这个评估就是所谓的 validation system chaincode（VSCC）的任务，这是一个静态库，是区块链配置的一部分，负责根据为链码配置的背书策略来验证背书。如果背书条件没有被满足，则这个交易被标记为非法，并且其效力将会被忽略。
2. **read-write conflict check**：读写冲突检查会对区块中所有事务按顺序进行检查。对于每个交易，他会对比这个 key 对应的现在的 version 以及在 readset 中这个 key 对应的 version，确保这两个 version 是相同的（否则说明在这之前已经有更新的写入操作了）。如果 version 不匹配，则交易被标记为非法，并且忽略其效力。
3. **ledger update phase**：这个步骤里，区块会被追加到本地的账本，并且更新区块链的状态。当区块加入到账本的时候，前两个步骤的有效性价差的结果也会被持久化，以比特位的形式来表示这个区块中有效的交易。这有利于迅速恢复状态。此外，所有的状态更新都是通过将 writeset 中所有的键值对写入到本地状态来实现的。

Fabric 中默认的 VSCC 允许在为链码配置的背书者集合上添加一些单调的逻辑表达式。VSCC 验证了一组 peer 是满足这个表达式的，正如通过交易许可上的签名一样来验证是否满足。不同的 VSCC 政策可以静态的被配置，来满足不同的需求。

讨论一下设计要点。Fabric 的账本包含所有交易，包括那些被认为是无效的交易。这源于整体设计，与链码状态无关的排序服务产生了区块的链，而验证是由 peer 在完成共识后完成。这个特性对于某些需要在后续审计过程中跟踪非法交易的用例来说是比较重要的，这与其他区块链（如比特币和以太坊）形成对比，后者的账本只包含有效交易。此外，由于 Fabric 的许可性质，很容易检测那些试图通过用无效交易淹没网络来发动 DoS 攻击的客户。一种方法是根据政策将这些客户列入黑名单。此外，一个特定的部署可以实现交易费用，对交易调用进行收费，这将使 DoS 攻击的成本过高。

### fabric 组成元素

![Components of a Fabric peer.](fig5.png)

#### 成员服务（Membership Service）

membership service provider（MSP）维护着所有系统里的节点（包括客户端、peer 节点、排序服务节点），并且负责发放用于认证和授权的节点凭证。由于 Fabric 是许可的，所以节点之间的所有互动都是通过经过认证的消息进行的，通常通过数字签名来认证。成员服务包括每个节点上的一个组件，它可以认证交易，验证交易的完整性，签署和验证认可，以及认证其他区块链操作。密钥管理和节点注册的工具也是 MSP 的一部分。

MSP 是一个抽象的概念，可能会有不同的实现。Fabric 中的默认 MSP 实现处理标准的 PKI 方法，实现基于数字签名的认证，并可容纳商业认证机构（CA）。Fabric 还提供了一个独立的 CA，称为 Fabric-CA。此外，还允许有其他的 MSP 实现，例如，依靠匿名凭证授权客户发起交易，不将其与身份联系起来。

Fabric 允许以两种模式建立区块链网络。在离线模式下，凭证由 CA 生成。peer 节点和排序节点只能在离线模式下注册。对于客户端的注册，Fabric-CA 提供了一个在线模式，可以向他们发放加密证书。MSP 配置必须确保所有节点，特别是所有 peer 节点，都能识别出相同的身份和认证。

MSP 允许身份联盟，例如，当多个组织运营一个区块链网络时。每个组织向自己的成员发放身份，每个 peer 都能识别所有组织的成员。这可以通过多个 MSP 实例来实现，例如在每个组织和一个 MSP 之间创建一个映射。

#### 排序服务（Ordering Service）

排序服务管理的是各个通道。对于每个通道，他都提供了下面的几个服务：

1. atomic broadcast，对于交易产生的排序进行原子广播，实现了`broadcast`和`deliver`调用。
2. reconfiguration，通过成员广播一个配置更新事务（configuration update transaction）来重新配置通道。
3. access control，在排序服务作为受信任实体的配置中，可以选择访问控制，将交易的广播和区块的接收限制在指定的客户和 peer 节点身上。

排序服务是通过系统通道（system channel）上的创世区块（genesis block）来引导的。这个区块带有一个配置事务（configuration transaction），它定义了排序服务的属性。

目前的生产实现由排序服务节点（ordering service nodes-OSNs）组成，这些节点实现了这里描述的操作，并通过系统通道进行通信。实际的原子广播功能是由 Apache Kafka 的一个实例提供的，该实例基于 ZooKeeper，提供了可扩展的发布-订阅消息和强大的一致性。Kafka 可以在独立于 OSN 的物理节点上运行。OSNs 作为 peer 节点和 Kafka 之间的代理。

一个 OSN 直接将新收到的事务注入原子广播（例如注入 Kafka 代理）。其他的 OSN 对从原子广播中收到的交易进行批处理并形成块。只要满足三个条件之一，一个块就会被切割。

1. 区块包含指定的最大交易数；
2. 区块达到最大尺寸（字节）；
3. 自收到新区块的第一个交易以来已经过了一定的时间，如下所述。

这个批处理过程是确定的，因此在所有节点产生相同的块。很容易看出，前两个条件是微不足道的，因为从原子广播中收到的交易流是确定的。为了确保第三种情况下生成确定性的区块，当一个节点从原子广播中读到一个区块的第一个交易时，它就会启动一个计时器。如果计时器过期时，该区块还没有被切割，OSN 就会在信道上广播一个特殊的 time-to-cut 交易，该交易表明它打算切割的区块的序列号。另一方面，每个 OSN 在收到给定区块编号的第一个 time-to-cut 交易后，立即切割一个新区块。因为这个交易是自动地被传送到所有互相连接的 OSN 上，因此他们在区块中会包含一个相同的交易列表。OSNs 将最近交付的区块范围直接保存在他们的文件系统中，因此他们可以回复 peer 节点的 deliver 调用（搜索区块）。

基于 Kafka 的排序服务是目前可用的三种实现方式之一。一个名为 Solo 的中心化排序服务在一个节点上运行，是用于开发的。一个基于 BFT-SMaRt 的概念验证（proof-of-concept）的排序服务也已经可用；它确保了原子广播服务，但还没有重新配置和访问控制。这说明了 Fabric 中共识的模块化。

#### Gossip 数据传播协议

将 execution，ordering，validation 三个阶段分离的好处之一是这三者能够独立地进行扩展。然而，由于大多数共识算法（在 CFT 和 BFT 模型中）都是有带宽限制的，所以排序服务的吞吐量被其节点的网络容量限制了。共识不能通过增加节点来扩大规模，相反，结点量变多后吞吐量会减少。

然而，由于排序和验证是分离的，我们关心的是在排序阶段之后有效地将执行结果广播给所有 peer 节点进行验证。这一点以及向新加入的 peer 节点和长期断开连接的 peer 节点的状态转移，就是 gossip 组件的目标。Fabric gossip 利用**流行性组播**（epidemic multicast）来达到这个目的。区块是由排序服务签名的，这意味着 peer 节点在收到所有区块后，可以独立地组装区块链并验证其完整性。

gossip 的通信层是基于 gRPC 的，并利用 TLS 与相互认证，这使得每一方都能将 TLS 凭证与远程 peer 节点的身份绑定。gossip 组件维护系统中在线 peer 节点的最新成员视图（membership view）。所有 peer 节点从定期传播的成员数据中独立地建立一个本地视图。此外，一个 peer 节点可以在崩溃或网络中断后重新连接到该视图。

Fabric gossip 使用两个阶段进行信息传播：在 **push** 期间，每个 peer 节点从成员视图中随机选择一组活跃的邻居，并将信息转发给他们；在 **pull**期间，每个 peer 节点定期探测一组随机选择的 peer 节点，并请求丢失信息。已经证明，串联使用这两种方法对于优化利用可用带宽和确保所有 peer 节点以高概率收到所有消息至关重要。为了减少从排序节点向网络发送区块的负载，该协议还选择了一个领导 peer 节点，代表他们排序服务中 pull 区块，并启动 gossip 分发。这种机制对领导者的失败是有弹性的。

#### 账本（Ledger）

每个 peer 节点都维护着账本和在持久化存储上的状态，使能了 simulation, validation 和 ledger-update 三个状态。大体上，它是由一个区块存储（block store）和一个事务管理器（peer transaction manager）组成的。

**区块存储**（block store）是交易区块的持久化版本，本质上是一组仅追加的文件。区块存储同时还维护着一些用于随机访问区块、事务的索引。

**PTM**（peer transaction manager）维护着带有版本号的以 (key, value) 形式存储的最新的状态。他保存着类似于（key，value，version）这样的一个由链码存储的三元组，保存着以 key 为主键的，最新的 value。version 字段包括区块序列号和区块内的交易（存储条目）的序列号。这样的设计使得 version 是唯一的，且单调递增的。PTM 使用 LevelDB 或者 CouchDB 来实现这么一个本地 kv 存储。

在模拟过程中，PTM 为事务提供最新状态的稳定快照。PTM 在 readset 中记录了由 GetState 访问的每个条目的元组 (key, ver)，在 writeset 中记录了由 PutState 更新的每个条目 (key, val)。此外，PTM 支持范围查询，为此它计算查询结果的加密哈希值（一组（key, ver)），并将查询字符串本身和哈希值添加到 readset 中。

对于交易验证环节，PTM 按顺序验证一个区块中的所有交易行为。这将检查一个交易是否与之前的任何交易（在该区块内或之前的）相冲突。对于 readset 中的任何一个键，如果 readset 中记录的版本与最新状态下的版本不同（假设所有先前的有效交易都已提交），那么 PTM 就会将该交易标记为无效。对于范围查询，PTM 重新执行查询，并将哈希值与 readset 中的哈希值进行比较，以确保不发生幻读。这种读写冲突模式导致了单拷贝序列化（one-copy serializability）。

账本组件允许在更新状态时发生下面的场景。ledger 组件在收到一个新区块之后，PTM 已经进行了验证，并在区块内使用 bit mask 将交易标记为有效或无效。现在账本组件将区块写入 block store，并且刷盘，然后更新 block store 的索引。然后，PTM 会把 writeset 中所有有效交易的状态变化应用到本地的带版本号的存储。最后，他会计算并且持久化一个叫做 savepoint 的值，表示最大的已经应用到状态的区块号。savepoint 是用来在出现故障时恢复到最新状态的。

#### 执行链码 (Chaincode Execution)

链码是在一个与其他 peer 松耦合的环境中执行的，它支持添加新的链码编程语言。目前支持 go，java 和 node.js。

每个链码都在 Docker 容器环境中以一个单独程序中运行，这使得链码之间以及与 peer 节点之间相互隔离。这也简化了对链码生命周期的管理（即启动、停止或中止链码）。链码和 peer 节点使用 gRPC 消息来进行通信。通过这种松散耦合的方式，peer 不需要知道链码到底是用什么语言编写的。

与应用链码相比，系统链码直接在 peer 进程中运行。系统链码可以实现 fabric 所需要的特定的函数，可能在用户链码的隔离力度过于严格时被调用。

#### 配置和系统链码

fabric 是通过通道配置（channel configuration）和特殊链码（system chaincode）来实现定制化的。

fabric 中的每个通道形成一个逻辑区块链。一个区块的配置被保存在元数据中，这些元数据被持久化在特殊的**配置区块**上（configuration block），每个配置区块包含整个通道的配置，但不包含任何交易。每个区块链以一个配置区块开始，就是所谓的创世区块，来引导通道。通道的配置包括：

1. 为参与网络的 peer 节点定义 MSPs。
2. OSNs 的网络地址
3. 共识与排序服务共享的配置，比如 batch size 和 timeouts。
4. 定义管理访问排序服务操作的规则，排序服务操作包括 broadcast 和 deliver。
5. 定义通道配置的每一部分如何被修改的规则。

通道的配置可以用通道配置更新事务（channel configuration update transaction）来更新。该事务包含对配置所做的修改的再声明，以及一组签名。排序服务节点通过当前的配置来验证修改是否被授权来评估这次更新是否有效，即，只有被授权的带签名的修改才能被判定为有效。然后，排序节点生成一个新的配置区块，其中嵌入了新的配置和配置更新事务（configuration update transaction）。收到该块的 peer 节点根据当前配置验证配置更新事务是否被授权；如果有效，他们就更新他们当前的配置。

应用链码的部署参考了 endorsement system chaincode(ESCC) 和 validation system chaincode(VSCC) 两个链码。选择这两个链码是为了 ESCC 的输出（endorsement）可以作为 VSCC 的输入的一部分而得到验证。ESCC 将一个提案和这个体验的模拟结果作为输入，如果结果是令人满意的，则 ESCC 产生一个包含结果和背书的回复。在默认的 ESCC 中，背书只是 peer 节点的本地身份的签名。VSCC 将交易作为输入，并输出这个交易是否有效。对于默认的 VSCC，将根据为链码指定的背书政策收集和评估背书。此外，系统链码还实现了其他支持函数，如链码的生命周期。
